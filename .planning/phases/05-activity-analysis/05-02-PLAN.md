---
phase: 05-activity-analysis
plan: 02
type: execute
wave: 2
depends_on: ["05-01"]
files_modified:
  - internal/metrics/cloudwatch.go
  - internal/metrics/collector.go
  - cmd/server/main.go
  - go.mod
autonomous: true

must_haves:
  truths:
    - "System fetches CloudWatch metrics every 15 minutes"
    - "System collects CPUUtilization, DatabaseConnections, ReadIOPS, WriteIOPS"
    - "Metrics are stored as hourly aggregates in the database"
    - "Failed requests are retried 3 times before marking as failed"
    - "Stopped instances are skipped (no metrics available)"
  artifacts:
    - path: "internal/metrics/cloudwatch.go"
      provides: "CloudWatch API client wrapper"
      exports: ["CloudWatchClient", "NewCloudWatchClient", "GetRDSMetrics"]
    - path: "internal/metrics/collector.go"
      provides: "Background metrics collection service"
      exports: ["MetricsCollector", "NewMetricsCollector", "RunContinuous"]
    - path: "cmd/server/main.go"
      provides: "MetricsCollector initialization and startup"
      contains: "metricsCollector"
  key_links:
    - from: "internal/metrics/collector.go"
      to: "internal/metrics/store.go"
      via: "Stores collected metrics"
      pattern: "metricsStore\\.UpsertHourlyMetric"
    - from: "internal/metrics/cloudwatch.go"
      to: "aws-sdk-go-v2/service/cloudwatch"
      via: "CloudWatch API calls"
      pattern: "cloudwatch\\.GetMetricStatistics"
    - from: "cmd/server/main.go"
      to: "internal/metrics/collector.go"
      via: "Background goroutine"
      pattern: "metricsCollector\\.RunContinuous"
---

<objective>
Implement CloudWatch client and background MetricsCollector service that fetches metrics every 15 minutes.

Purpose: Core metrics ingestion pipeline that enables activity analysis. Collects CPU, connections, read/write IOPS from CloudWatch for all running AWS RDS instances and stores hourly aggregates.

Output:
- `internal/metrics/cloudwatch.go` - CloudWatch API wrapper with retry logic
- `internal/metrics/collector.go` - Background service running on 15-minute ticker
- Updated `cmd/server/main.go` to start MetricsCollector
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/phases/05-activity-analysis/05-CONTEXT.md
@.planning/phases/05-activity-analysis/05-RESEARCH.md
@.planning/phases/05-activity-analysis/05-01-SUMMARY.md
@internal/metrics/store.go
@internal/models/models.go
@internal/provider/aws/rds.go
@internal/discovery/discovery.go
@cmd/server/main.go
</context>

<tasks>

<task type="auto">
  <name>Task 1: Add CloudWatch SDK dependency</name>
  <files>go.mod</files>
  <action>
Run:
```bash
go get github.com/aws/aws-sdk-go-v2/service/cloudwatch@latest
```

This adds the CloudWatch client to go.mod. The project already uses aws-sdk-go-v2 for RDS, so this is the matching v2 package.

Verify by checking go.mod contains:
`github.com/aws/aws-sdk-go-v2/service/cloudwatch`
  </action>
  <verify>
grep "cloudwatch" go.mod shows the dependency
  </verify>
  <done>
CloudWatch SDK dependency added to go.mod
  </done>
</task>

<task type="auto">
  <name>Task 2: Create CloudWatch client wrapper</name>
  <files>internal/metrics/cloudwatch.go</files>
  <action>
Create internal/metrics/cloudwatch.go with CloudWatch API wrapper:

```go
package metrics

import (
    "context"
    "errors"
    "fmt"
    "time"

    "github.com/aws/aws-sdk-go-v2/aws"
    "github.com/aws/aws-sdk-go-v2/config"
    "github.com/aws/aws-sdk-go-v2/credentials"
    "github.com/aws/aws-sdk-go-v2/service/cloudwatch"
    "github.com/aws/aws-sdk-go-v2/service/cloudwatch/types"

    "snoozeql/internal/models"
)

// CloudWatchClient wraps the AWS CloudWatch client for RDS metrics
type CloudWatchClient struct {
    client *cloudwatch.Client
    region string
}

// NewCloudWatchClient creates a new CloudWatch client with credentials
func NewCloudWatchClient(region, accessKey, secretKey string) (*CloudWatchClient, error) {
    var cfg aws.Config
    var err error

    if accessKey != "" && secretKey != "" {
        cfg, err = config.LoadDefaultConfig(context.Background(),
            config.WithRegion(region),
            config.WithCredentialsProvider(credentials.NewStaticCredentialsProvider(accessKey, secretKey, "")))
    } else {
        cfg, err = config.LoadDefaultConfig(context.Background(),
            config.WithRegion(region))
    }
    if err != nil {
        return nil, fmt.Errorf("failed to load AWS config: %w", err)
    }

    return &CloudWatchClient{
        client: cloudwatch.NewFromConfig(cfg),
        region: region,
    }, nil
}

// RDSMetrics holds the collected metrics for an RDS instance
type RDSMetrics struct {
    InstanceID string
    Timestamp  time.Time
    CPU        *MetricValue
    Connections *MetricValue
    ReadIOPS   *MetricValue
    WriteIOPS  *MetricValue
}

// MetricValue holds a single metric's statistics
type MetricValue struct {
    Avg float64
    Max float64
    Min float64
}

// GetRDSMetrics fetches all relevant metrics for an RDS instance
// Returns metrics for the last hour, aggregated
func (c *CloudWatchClient) GetRDSMetrics(ctx context.Context, dbInstanceID string) (*RDSMetrics, error) {
    endTime := time.Now().UTC()
    startTime := endTime.Add(-1 * time.Hour)

    metrics := &RDSMetrics{
        InstanceID: dbInstanceID,
        Timestamp:  endTime.Truncate(time.Hour),
    }

    // Fetch each metric type
    cpu, err := c.getMetricWithRetry(ctx, dbInstanceID, models.MetricCPUUtilization, startTime, endTime)
    if err == nil {
        metrics.CPU = cpu
    }

    conns, err := c.getMetricWithRetry(ctx, dbInstanceID, models.MetricDatabaseConnections, startTime, endTime)
    if err == nil {
        metrics.Connections = conns
    }

    readIOPS, err := c.getMetricWithRetry(ctx, dbInstanceID, models.MetricReadIOPS, startTime, endTime)
    if err == nil {
        metrics.ReadIOPS = readIOPS
    }

    writeIOPS, err := c.getMetricWithRetry(ctx, dbInstanceID, models.MetricWriteIOPS, startTime, endTime)
    if err == nil {
        metrics.WriteIOPS = writeIOPS
    }

    return metrics, nil
}

// getMetricWithRetry fetches a single metric with 3 retry attempts
func (c *CloudWatchClient) getMetricWithRetry(ctx context.Context, dbInstanceID, metricName string, start, end time.Time) (*MetricValue, error) {
    var lastErr error
    
    for attempt := 0; attempt < 3; attempt++ {
        value, err := c.getMetric(ctx, dbInstanceID, metricName, start, end)
        if err == nil {
            return value, nil
        }
        lastErr = err

        // Check for throttling - exponential backoff
        var limitErr *types.LimitExceededException
        if errors.As(err, &limitErr) {
            time.Sleep(time.Duration(1<<attempt) * time.Second)
            continue
        }

        // For other errors, check if retryable
        if !isRetryableError(err) {
            return nil, err
        }
        time.Sleep(time.Duration(1<<attempt) * 100 * time.Millisecond)
    }
    
    return nil, fmt.Errorf("failed after 3 retries: %w", lastErr)
}

// getMetric fetches a single CloudWatch metric
func (c *CloudWatchClient) getMetric(ctx context.Context, dbInstanceID, metricName string, start, end time.Time) (*MetricValue, error) {
    input := &cloudwatch.GetMetricStatisticsInput{
        Namespace:  aws.String("AWS/RDS"),
        MetricName: aws.String(metricName),
        Dimensions: []types.Dimension{
            {
                Name:  aws.String("DBInstanceIdentifier"),
                Value: aws.String(dbInstanceID),
            },
        },
        StartTime:  aws.Time(start),
        EndTime:    aws.Time(end),
        Period:     aws.Int32(3600), // 1 hour
        Statistics: []types.Statistic{
            types.StatisticAverage,
            types.StatisticMaximum,
            types.StatisticMinimum,
        },
    }

    output, err := c.client.GetMetricStatistics(ctx, input)
    if err != nil {
        return nil, fmt.Errorf("GetMetricStatistics failed for %s: %w", metricName, err)
    }

    if len(output.Datapoints) == 0 {
        return nil, fmt.Errorf("no datapoints for %s", metricName)
    }

    // Use the most recent datapoint
    dp := output.Datapoints[0]
    for _, d := range output.Datapoints[1:] {
        if d.Timestamp.After(*dp.Timestamp) {
            dp = d
        }
    }

    return &MetricValue{
        Avg: aws.ToFloat64(dp.Average),
        Max: aws.ToFloat64(dp.Maximum),
        Min: aws.ToFloat64(dp.Minimum),
    }, nil
}

// isRetryableError checks if an error is transient and should be retried
func isRetryableError(err error) bool {
    if err == nil {
        return false
    }
    // Network errors, timeouts, and server errors are retryable
    errStr := err.Error()
    return contains(errStr, "timeout") || 
           contains(errStr, "connection") ||
           contains(errStr, "503") ||
           contains(errStr, "500")
}

func contains(s, substr string) bool {
    return len(s) >= len(substr) && 
           (s == substr || 
            len(s) > len(substr) && 
            (s[:len(substr)] == substr || 
             s[len(s)-len(substr):] == substr ||
             containsMiddle(s, substr)))
}

func containsMiddle(s, substr string) bool {
    for i := 0; i <= len(s)-len(substr); i++ {
        if s[i:i+len(substr)] == substr {
            return true
        }
    }
    return false
}
```

Key decisions:
- Uses GetMetricStatistics (simpler than GetMetricData for single metrics)
- 3 retry attempts with exponential backoff for throttling
- Fetches last 1 hour of data with 1-hour period for hourly aggregation
- Returns nil for individual metrics on failure (partial success)
  </action>
  <verify>
go build ./internal/metrics/... compiles without errors
  </verify>
  <done>
CloudWatchClient created with GetRDSMetrics, retry logic, and support for all 4 metric types
  </done>
</task>

<task type="auto">
  <name>Task 3: Create MetricsCollector service</name>
  <files>internal/metrics/collector.go</files>
  <action>
Create internal/metrics/collector.go with background collection service:

```go
package metrics

import (
    "context"
    "fmt"
    "log"
    "sync"
    "time"

    "snoozeql/internal/models"
    "snoozeql/internal/store"
)

// MetricsCollector manages background metric collection from CloudWatch
type MetricsCollector struct {
    metricsStore   *MetricsStore
    instanceStore  *store.InstanceStore
    accountStore   *store.CloudAccountStore
    interval       time.Duration
    clients        map[string]*CloudWatchClient // accountID_region -> client
    clientsMu      sync.RWMutex
    enabled        bool
}

// NewMetricsCollector creates a new metrics collector
func NewMetricsCollector(
    metricsStore *MetricsStore,
    instanceStore *store.InstanceStore,
    accountStore *store.CloudAccountStore,
    intervalMinutes int,
) *MetricsCollector {
    return &MetricsCollector{
        metricsStore:  metricsStore,
        instanceStore: instanceStore,
        accountStore:  accountStore,
        interval:      time.Duration(intervalMinutes) * time.Minute,
        clients:       make(map[string]*CloudWatchClient),
        enabled:       true,
    }
}

// RunContinuous runs the metrics collection on the configured interval
func (c *MetricsCollector) RunContinuous(ctx context.Context) {
    if !c.enabled {
        return
    }

    // Run immediately on startup
    if err := c.CollectAll(ctx); err != nil {
        log.Printf("Initial metrics collection failed: %v", err)
    }

    ticker := time.NewTicker(c.interval)
    defer ticker.Stop()

    for {
        select {
        case <-ctx.Done():
            log.Println("Metrics collector shutting down")
            return
        case <-ticker.C:
            if err := c.CollectAll(ctx); err != nil {
                log.Printf("Metrics collection failed: %v", err)
            }
        }
    }
}

// CollectAll collects metrics for all running AWS RDS instances
func (c *MetricsCollector) CollectAll(ctx context.Context) error {
    log.Println("Starting metrics collection cycle...")
    
    instances, err := c.instanceStore.ListInstances(ctx)
    if err != nil {
        return fmt.Errorf("failed to list instances: %w", err)
    }

    var collected, skipped, failed int
    
    for _, instance := range instances {
        // Skip non-AWS instances (GCP not implemented yet per CONTEXT.md)
        if instance.Provider != "aws" {
            skipped++
            continue
        }

        // Skip stopped instances (no metrics available per RESEARCH.md)
        if instance.Status != "available" && instance.Status != "running" {
            skipped++
            continue
        }

        // Get or create CloudWatch client for this account/region
        client, err := c.getClient(ctx, instance)
        if err != nil {
            log.Printf("Failed to get CloudWatch client for %s: %v", instance.Name, err)
            failed++
            continue
        }

        // Collect metrics for this instance
        if err := c.collectInstance(ctx, client, instance); err != nil {
            log.Printf("Failed to collect metrics for %s: %v", instance.Name, err)
            failed++
            continue
        }

        collected++
    }

    log.Printf("Metrics collection complete: collected=%d, skipped=%d, failed=%d", collected, skipped, failed)
    return nil
}

// collectInstance collects and stores metrics for a single instance
func (c *MetricsCollector) collectInstance(ctx context.Context, client *CloudWatchClient, instance models.Instance) error {
    // ProviderID is the DBInstanceIdentifier for RDS
    metrics, err := client.GetRDSMetrics(ctx, instance.ProviderID)
    if err != nil {
        return fmt.Errorf("GetRDSMetrics failed: %w", err)
    }

    // Store each metric type
    if metrics.CPU != nil {
        if err := c.storeMetric(ctx, instance.ID, models.MetricCPUUtilization, metrics.Timestamp, metrics.CPU); err != nil {
            log.Printf("Failed to store CPU metric for %s: %v", instance.Name, err)
        }
    }

    if metrics.Connections != nil {
        if err := c.storeMetric(ctx, instance.ID, models.MetricDatabaseConnections, metrics.Timestamp, metrics.Connections); err != nil {
            log.Printf("Failed to store Connections metric for %s: %v", instance.Name, err)
        }
    }

    if metrics.ReadIOPS != nil {
        if err := c.storeMetric(ctx, instance.ID, models.MetricReadIOPS, metrics.Timestamp, metrics.ReadIOPS); err != nil {
            log.Printf("Failed to store ReadIOPS metric for %s: %v", instance.Name, err)
        }
    }

    if metrics.WriteIOPS != nil {
        if err := c.storeMetric(ctx, instance.ID, models.MetricWriteIOPS, metrics.Timestamp, metrics.WriteIOPS); err != nil {
            log.Printf("Failed to store WriteIOPS metric for %s: %v", instance.Name, err)
        }
    }

    return nil
}

// storeMetric stores a single metric value
func (c *MetricsCollector) storeMetric(ctx context.Context, instanceID, metricName string, hour time.Time, value *MetricValue) error {
    m := &models.HourlyMetric{
        InstanceID:  instanceID,
        MetricName:  metricName,
        Hour:        hour,
        AvgValue:    value.Avg,
        MaxValue:    value.Max,
        MinValue:    value.Min,
        SampleCount: 1,
    }
    return c.metricsStore.UpsertHourlyMetric(ctx, m)
}

// getClient returns or creates a CloudWatch client for the instance's account/region
func (c *MetricsCollector) getClient(ctx context.Context, instance models.Instance) (*CloudWatchClient, error) {
    // Key by account+region since each region needs its own client
    key := fmt.Sprintf("%s_%s", instance.CloudAccountID, instance.Region)

    c.clientsMu.RLock()
    client, exists := c.clients[key]
    c.clientsMu.RUnlock()

    if exists {
        return client, nil
    }

    // Create new client - need to get credentials from account store
    account, err := c.accountStore.GetCloudAccount(instance.CloudAccountID)
    if err != nil {
        return nil, fmt.Errorf("failed to get cloud account: %w", err)
    }

    // Extract AWS credentials
    accessKey, _ := account.Credentials["aws_access_key_id"].(string)
    secretKey, _ := account.Credentials["aws_secret_access_key"].(string)

    if accessKey == "" || secretKey == "" {
        return nil, fmt.Errorf("missing AWS credentials for account %s", account.Name)
    }

    client, err = NewCloudWatchClient(instance.Region, accessKey, secretKey)
    if err != nil {
        return nil, fmt.Errorf("failed to create CloudWatch client: %w", err)
    }

    c.clientsMu.Lock()
    c.clients[key] = client
    c.clientsMu.Unlock()

    return client, nil
}

// SetEnabled enables or disables the collector
func (c *MetricsCollector) SetEnabled(enabled bool) {
    c.enabled = enabled
}
```

Key decisions:
- 15-minute interval per CONTEXT.md
- Skips non-AWS and stopped instances
- Caches CloudWatch clients per account/region combination
- Uses mutex for thread-safe client cache
- Logs collection stats for monitoring
  </action>
  <verify>
go build ./internal/metrics/... compiles without errors
  </verify>
  <done>
MetricsCollector created with RunContinuous, CollectAll, per-instance collection, and client caching
  </done>
</task>

<task type="auto">
  <name>Task 4: Integrate MetricsCollector into main.go</name>
  <files>cmd/server/main.go</files>
  <action>
Update cmd/server/main.go to initialize and start the MetricsCollector:

1. Add import:
```go
"snoozeql/internal/metrics"
```

2. Add global variable after eventStore (around line 38):
```go
metricsStore     *metrics.MetricsStore
metricsCollector *metrics.MetricsCollector
```

3. After scheduleStore initialization (around line 182), add:
```go
// Initialize metrics store and collector
metricsStore = metrics.NewMetricsStore(db)
metricsCollector = metrics.NewMetricsCollector(
    metricsStore,
    instanceStore,
    accountStore,
    15, // 15-minute collection interval per CONTEXT.md
)
```

4. After discovery RunContinuous goroutine (around line 188), add:
```go
// Start metrics collection in background
go metricsCollector.RunContinuous(ctx)
log.Printf("âœ“ Started metrics collector (15-minute interval)")
```

This wires up the collector to run alongside the discovery service.
  </action>
  <verify>
go build ./cmd/server/... compiles without errors
  </verify>
  <done>
MetricsCollector initialized and started in main.go with 15-minute interval
  </done>
</task>

</tasks>

<verification>
1. CloudWatch SDK added: `grep "cloudwatch" go.mod`
2. All packages compile: `go build ./...`
3. No import cycles: `go build -v ./internal/metrics/...`
4. Server starts: `go run cmd/server/main.go` (verify log output shows collector started)
</verification>

<success_criteria>
- [ ] CloudWatch SDK dependency added to go.mod
- [ ] CloudWatchClient fetches CPUUtilization, DatabaseConnections, ReadIOPS, WriteIOPS
- [ ] CloudWatchClient retries failed requests 3 times with exponential backoff
- [ ] MetricsCollector runs on 15-minute interval
- [ ] MetricsCollector skips non-AWS and stopped instances
- [ ] MetricsCollector stores metrics via MetricsStore.UpsertHourlyMetric
- [ ] main.go starts MetricsCollector in background goroutine
- [ ] All Go code compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/05-activity-analysis/05-02-SUMMARY.md`
</output>
