---
phase: 05-activity-analysis
plan: 01
type: execute
wave: 1
depends_on: []
files_modified:
  - deployments/docker/migrations/005_metrics_hourly.sql
  - internal/metrics/store.go
  - internal/models/models.go
autonomous: true

must_haves:
  truths:
    - "Metrics hourly table exists in database"
    - "MetricsStore can insert hourly metric aggregates"
    - "MetricsStore can query metrics by instance and time range"
    - "Existing metric rows are updated (UPSERT) when new samples arrive"
  artifacts:
    - path: "deployments/docker/migrations/005_metrics_hourly.sql"
      provides: "Database schema for hourly metrics storage"
      contains: "CREATE TABLE metrics_hourly"
    - path: "internal/metrics/store.go"
      provides: "MetricsStore with CRUD operations"
      exports: ["MetricsStore", "NewMetricsStore", "UpsertHourlyMetric", "GetMetricsByInstance"]
    - path: "internal/models/models.go"
      provides: "HourlyMetric model struct"
      contains: "HourlyMetric struct"
  key_links:
    - from: "internal/metrics/store.go"
      to: "internal/store/postgres.go"
      via: "Uses Postgres connection"
      pattern: "store\\.Postgres"
---

<objective>
Create database schema and MetricsStore for persisting hourly metric aggregates.

Purpose: Foundation for storing CloudWatch metrics that will be collected every 15 minutes and aggregated hourly. Without this, the collector has nowhere to persist data.

Output: 
- Migration file `005_metrics_hourly.sql` with metrics_hourly table
- `internal/metrics/store.go` with MetricsStore for CRUD operations
- HourlyMetric model in `internal/models/models.go`
</objective>

<execution_context>
@~/.config/opencode/get-shit-done/workflows/execute-plan.md
@~/.config/opencode/get-shit-done/templates/summary.md
</execution_context>

<context>
@.planning/PROJECT.md
@.planning/ROADMAP.md
@.planning/STATE.md
@.planning/phases/05-activity-analysis/05-CONTEXT.md
@.planning/phases/05-activity-analysis/05-RESEARCH.md
@internal/store/postgres.go
@internal/models/models.go
@deployments/docker/migrations/001_base_schema.sql
</context>

<tasks>

<task type="auto">
  <name>Task 1: Create metrics_hourly migration</name>
  <files>deployments/docker/migrations/005_metrics_hourly.sql</files>
  <action>
Create migration file with:

```sql
-- Hourly aggregated metrics from CloudWatch
CREATE TABLE metrics_hourly (
    id UUID PRIMARY KEY DEFAULT uuid_generate_v4(),
    instance_id UUID NOT NULL REFERENCES instances(id) ON DELETE CASCADE,
    metric_name VARCHAR(50) NOT NULL,  -- CPUUtilization, DatabaseConnections, ReadIOPS, WriteIOPS
    hour TIMESTAMPTZ NOT NULL,          -- Truncated to hour in UTC
    avg_value FLOAT NOT NULL,
    max_value FLOAT NOT NULL,
    min_value FLOAT NOT NULL,
    sample_count INT NOT NULL DEFAULT 1,
    created_at TIMESTAMPTZ DEFAULT NOW(),
    updated_at TIMESTAMPTZ DEFAULT NOW(),
    UNIQUE(instance_id, metric_name, hour)
);

-- Index for efficient time-range queries per instance
CREATE INDEX idx_metrics_hourly_instance_time ON metrics_hourly(instance_id, hour DESC);
-- Index for retention cleanup queries
CREATE INDEX idx_metrics_hourly_hour ON metrics_hourly(hour DESC);

-- Update trigger for updated_at
CREATE TRIGGER update_metrics_hourly_updated_at BEFORE UPDATE ON metrics_hourly
    FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

COMMENT ON TABLE metrics_hourly IS 'Hourly aggregated CloudWatch metrics for activity analysis';
```

This schema supports:
- UPSERT with ON CONFLICT for incremental aggregation
- Efficient per-instance time-range queries
- 14-day retention (cleanup via scheduled job)
  </action>
  <verify>
File exists at deployments/docker/migrations/005_metrics_hourly.sql and contains CREATE TABLE metrics_hourly
  </verify>
  <done>
Migration file creates metrics_hourly table with correct schema, indexes, and constraints
  </done>
</task>

<task type="auto">
  <name>Task 2: Add HourlyMetric model</name>
  <files>internal/models/models.go</files>
  <action>
Add HourlyMetric struct to models.go after the Saving struct:

```go
// HourlyMetric represents an hourly aggregated metric from CloudWatch
type HourlyMetric struct {
    ID          string    `json:"id" db:"id"`
    InstanceID  string    `json:"instance_id" db:"instance_id"`
    MetricName  string    `json:"metric_name" db:"metric_name"`  // CPUUtilization, DatabaseConnections, etc.
    Hour        time.Time `json:"hour" db:"hour"`                // Truncated to hour in UTC
    AvgValue    float64   `json:"avg_value" db:"avg_value"`
    MaxValue    float64   `json:"max_value" db:"max_value"`
    MinValue    float64   `json:"min_value" db:"min_value"`
    SampleCount int       `json:"sample_count" db:"sample_count"`
    CreatedAt   time.Time `json:"created_at" db:"created_at"`
    UpdatedAt   time.Time `json:"updated_at" db:"updated_at"`
}

// MetricNames constants for supported CloudWatch metrics
const (
    MetricCPUUtilization      = "CPUUtilization"
    MetricDatabaseConnections = "DatabaseConnections"
    MetricReadIOPS            = "ReadIOPS"
    MetricWriteIOPS           = "WriteIOPS"
)
```
  </action>
  <verify>
grep -n "HourlyMetric" internal/models/models.go shows struct definition
  </verify>
  <done>
HourlyMetric model and MetricNames constants added to models.go
  </done>
</task>

<task type="auto">
  <name>Task 3: Create MetricsStore</name>
  <files>internal/metrics/store.go</files>
  <action>
Create new file internal/metrics/store.go with MetricsStore:

```go
package metrics

import (
    "context"
    "fmt"
    "time"

    "snoozeql/internal/models"
    "snoozeql/internal/store"
)

// MetricsStore provides metrics CRUD operations
type MetricsStore struct {
    db *store.Postgres
}

// NewMetricsStore creates a new metrics store
func NewMetricsStore(db *store.Postgres) *MetricsStore {
    return &MetricsStore{db: db}
}

// UpsertHourlyMetric inserts or updates an hourly metric aggregate
// Uses incremental averaging for existing hour buckets
func (s *MetricsStore) UpsertHourlyMetric(ctx context.Context, m *models.HourlyMetric) error {
    query := `
        INSERT INTO metrics_hourly (instance_id, metric_name, hour, avg_value, max_value, min_value, sample_count)
        VALUES ($1, $2, date_trunc('hour', $3::timestamptz), $4, $5, $6, $7)
        ON CONFLICT (instance_id, metric_name, hour) DO UPDATE SET
            avg_value = (metrics_hourly.avg_value * metrics_hourly.sample_count + EXCLUDED.avg_value) 
                        / (metrics_hourly.sample_count + 1),
            max_value = GREATEST(metrics_hourly.max_value, EXCLUDED.max_value),
            min_value = LEAST(metrics_hourly.min_value, EXCLUDED.min_value),
            sample_count = metrics_hourly.sample_count + 1,
            updated_at = NOW()
        RETURNING id`
    
    return s.db.QueryRow(ctx, query,
        m.InstanceID, m.MetricName, m.Hour,
        m.AvgValue, m.MaxValue, m.MinValue, m.SampleCount,
    ).Scan(&m.ID)
}

// GetMetricsByInstance returns metrics for an instance within a time range
func (s *MetricsStore) GetMetricsByInstance(ctx context.Context, instanceID string, start, end time.Time) ([]models.HourlyMetric, error) {
    query := `
        SELECT id, instance_id, metric_name, hour, avg_value, max_value, min_value, sample_count, created_at, updated_at
        FROM metrics_hourly
        WHERE instance_id = $1 AND hour >= $2 AND hour <= $3
        ORDER BY hour ASC, metric_name ASC`
    
    rows, err := s.db.Query(ctx, query, instanceID, start, end)
    if err != nil {
        return nil, fmt.Errorf("failed to query metrics: %w", err)
    }
    defer rows.Close()

    var metrics []models.HourlyMetric
    for rows.Next() {
        var m models.HourlyMetric
        err := rows.Scan(
            &m.ID, &m.InstanceID, &m.MetricName, &m.Hour,
            &m.AvgValue, &m.MaxValue, &m.MinValue, &m.SampleCount,
            &m.CreatedAt, &m.UpdatedAt,
        )
        if err != nil {
            return nil, fmt.Errorf("failed to scan metric: %w", err)
        }
        metrics = append(metrics, m)
    }
    
    if err := rows.Err(); err != nil {
        return nil, fmt.Errorf("rows error: %w", err)
    }
    
    return metrics, nil
}

// GetLatestMetrics returns the most recent metrics for an instance
func (s *MetricsStore) GetLatestMetrics(ctx context.Context, instanceID string) ([]models.HourlyMetric, error) {
    query := `
        SELECT DISTINCT ON (metric_name) 
            id, instance_id, metric_name, hour, avg_value, max_value, min_value, sample_count, created_at, updated_at
        FROM metrics_hourly
        WHERE instance_id = $1
        ORDER BY metric_name, hour DESC`
    
    rows, err := s.db.Query(ctx, query, instanceID)
    if err != nil {
        return nil, fmt.Errorf("failed to query latest metrics: %w", err)
    }
    defer rows.Close()

    var metrics []models.HourlyMetric
    for rows.Next() {
        var m models.HourlyMetric
        err := rows.Scan(
            &m.ID, &m.InstanceID, &m.MetricName, &m.Hour,
            &m.AvgValue, &m.MaxValue, &m.MinValue, &m.SampleCount,
            &m.CreatedAt, &m.UpdatedAt,
        )
        if err != nil {
            return nil, fmt.Errorf("failed to scan metric: %w", err)
        }
        metrics = append(metrics, m)
    }
    
    return metrics, rows.Err()
}

// DeleteOldMetrics removes metrics older than the retention period
// Called by a cleanup job to maintain 14-day retention
func (s *MetricsStore) DeleteOldMetrics(ctx context.Context, before time.Time) (int64, error) {
    return s.db.Exec(ctx, "DELETE FROM metrics_hourly WHERE hour < $1", before)
}

// HasSufficientData checks if an instance has enough data for pattern analysis
// Returns true if there are at least 24 hours of data (per CONTEXT.md requirement)
func (s *MetricsStore) HasSufficientData(ctx context.Context, instanceID string) (bool, error) {
    query := `
        SELECT COUNT(DISTINCT hour) >= 24
        FROM metrics_hourly
        WHERE instance_id = $1`
    
    var sufficient bool
    err := s.db.QueryRow(ctx, query, instanceID).Scan(&sufficient)
    return sufficient, err
}
```

Create the internal/metrics directory first if it doesn't exist.
  </action>
  <verify>
go build ./internal/metrics/... compiles without errors
  </verify>
  <done>
MetricsStore created with UpsertHourlyMetric, GetMetricsByInstance, GetLatestMetrics, DeleteOldMetrics, and HasSufficientData methods
  </done>
</task>

</tasks>

<verification>
1. Migration file exists: `ls deployments/docker/migrations/005_metrics_hourly.sql`
2. Models compile: `go build ./internal/models/...`
3. MetricsStore compiles: `go build ./internal/metrics/...`
4. Full build succeeds: `go build ./...`
</verification>

<success_criteria>
- [ ] Migration file creates metrics_hourly table with UNIQUE constraint and indexes
- [ ] HourlyMetric model exists in models.go with all required fields
- [ ] MetricsStore has UpsertHourlyMetric with ON CONFLICT incremental averaging
- [ ] MetricsStore has GetMetricsByInstance for time-range queries
- [ ] MetricsStore has HasSufficientData to check 24+ hours requirement
- [ ] All Go code compiles without errors
</success_criteria>

<output>
After completion, create `.planning/phases/05-activity-analysis/05-01-SUMMARY.md`
</output>
